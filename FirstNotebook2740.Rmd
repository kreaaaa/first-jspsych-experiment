---
title: "FirstNotebook2740"
output: html_document
date: "2024-10-15"
---

# install packages

```{r}
#install.packages("tidyverse")
install.packages("ggthemes")
```

# load packages

```{r}
library(tidyverse)
library(ggthemes)
```

#plot iris
#plus indicates one chunk of code

```{r}
ggplot(data = iris)+
  geom_point(mapping = aes(x = Petal.Width, y = Petal.Length, color = Species, 
  size = Species, shape = Species))
```


```{r}
ggplot(data = iris)+
  geom_point(mapping = aes (x = Sepal.Width, y = Sepal.Length, color = Species,
    size = Species, shape = Species))
```

#displaying aggregate data

```{r}
ggplot(data = iris) +
  geom_col(mapping = aes (x = Species, y = Petal.Length, fill = "coral2"))
```

#load class data

```{r}
savic = read_csv("class_data.csv")
```

#basic info

```{r}
nrow(savic)

ncol(savic)

colnames(savic)

mean(savic$correct)
#won't work bc our columns dont have consistent data that is cutesy for R
#can't do an average for a string
#chr = strings and can't do math on strings
```

#histogram of RT

```{r}
ggplot(data = savic) +
  geom_histogram(mapping = aes (x = as.numeric(rt)))

range(as.numeric(savic$rt))

```

#tidyverse verbs

```{r}
objectdata = read_csv("objects.csv") %>%
  mutate(rt = as.numeric(rt),
         weight = as.factor(weight),
         shape = as.factor(shape))
         

#piping. end before the last line of code
#only columns selected. no simplifying rows
#filter for rows
#check correct and wany id


condition_data = objectdata %>%
  filter(typeoftrial == "picture" & weight %in% c("Heavy", "Light") & shape %in% c("Normal", "Smashed") & correct == TRUE) %>%
  select(subject, rt, weight, shape, correct)


#descriptive statistics

object_agg = condition_data %>%
  group_by(weight, shape) %>%
  summarise(mean_rt = mean(rt),
            sd_rt = sd(rt))
```

#plot

```{r}
ggplot(data = object_agg) +
  geom_col(mapping = aes(x = shape, y = mean_rt, fill = weight), position = "dodge") +
  theme_minimal()+
  labs(title = "plots of RTs")+
  scale_fill_manual(values = c("firebrick2", "lightblue"))
```

#class data analysis

```{r}
savic = read_csv("class_data.csv") %>%
  mutate(rt = as.numeric(rt),
         relatedness = as.factor(relatedness),
         type = as.factor(type))

levels(savic$relatedness)
#can look at levels when factors 

savic %>% group_by(ID) %>% count()

#want to just look target trials per ID
#sooooo

x= savic%>% filter(typeoftrial == "target") %>%
  group_by(ID) %>% count() %>% 
  filter (n!=104)
mean(x$n)
#to make sure everyone has the same number of trials


savic %>% 
  filter (typeoftrial == "target") %>%
  pull(rt)

savic%>%
  pull(ID)%>% unique() %>% length()

```

#attention fixing typos

```{r}
attention_trials= savic%>% 
  filter(typeoftrial == "attention") %>% 
  select(ID, response, novel1, novel2, novel3, correct) %>% 
    rowwise() %>%
  mutate(response = ifelse(is.na(response), "blank", response)) %>%
  mutate(across(c(novel1, novel2, novel3), ~ replace_na(., "NOT_FOUND"))) %>% 
  mutate(edit_novel1 = adist(novel1, response),
         edit_novel2 = adist(novel2, response),
         edit_novel3 = adist(novel3, response)) %>% 
  mutate(revised_correct = ifelse(edit_novel1 <= 2 |
                                    edit_novel2 <= 2 |
                                    edit_novel3 <= 2,
                                    1, 0),
          mismatch = ifelse(correct == revised_correct, 0, 1)) %>%
  ungroup()

  
```

#summarizing accuracy for attention trials

```{r}
attention_trials  %>% 
  summarize(mean_accuracy = mean(revised_correct), 
            sd_accuracy = sd(revised_correct))

## summarize participant accuracy 
subject_attention_accuracy = attention_trials  %>% 
  group_by(ID)  %>% 
  summarize(mean_accuracy = mean(revised_correct))

# find IDs with less than 75% accuracy
low_acc_IDs = subject_attention_accuracy  %>% 
  filter(mean_accuracy < 0.75)  %>% 
  pull(ID)
```

#need to filter based on rt in priming !!!!!!!

```{r}
priming_data= savic%>% filter(typeoftrial == "target") %>%
  select (ID, rt, relatedness, prime, response,type, correct, block_number, target, correct_key) %>%
  filter(!is.na(rt), rt> 200, rt< 1500, correct == "TRUE", block_number == 1) %>%
  filter(relatedness %in% c("related", "unrelated") & type %in% c("direct", "shared")) %>%
filter(!ID %in% low_acc_IDs)
```

#plot

```{r}
priming_data %>%
  group_by(type, relatedness) %>%
  summarise(mean_rt = mean(rt)) %>%
  ggplot() +
  geom_col(mapping= aes(x= type, y= mean_rt, 
                        group= relatedness, fill= relatedness),
           position = "dodge") +
  theme_bw() +
  scale_fill_manual(values = c("firebrick2", "lightblue"))
```

#linear models

```{r}
data (women)

women %>%
ggplot (aes(x = weight, y = height))+
  geom_point() +
  geom_smooth (method = "lm") +
  theme_classic()
  
women_model= lm(data = women, height ~ weight)

summary(women_model)
#want coefficients to determine equation of the line 
#height = .287 (weight) + 25.7
# to assess model of best fit look at error
```

```{r}
#install.packages("car")
#to use only one function from a package 
car:: Anova(women_model)

# Weight significantly predicts height, (F, 13) = p < 0.001.
# data Y = model (X) + error)
```

#mean petal length for each species in iris dataset

```{r}
#put set in environment

data(iris)
View(iris)

iris %>%
        group_by(Species) %>%
        summarize(mean_length = mean(Petal.Length))

iris%>%
  ggplot (aes (x= Species, y = Petal.Length)) +
            geom_boxplot()
```

```{r}
iris_model = lm(data=iris, Petal.Length ~ Species)
car :: Anova(iris_model)
```
# Species significantly predicted petal length (F(2, 147)= 1180.2, p < .001 ).
#degrees of freedom always levels of IV - 1

```{r}
#install.packages("emmeans")
 emmeans :: emmeans (iris_model,
                     pairwise ~ Species,
                     adjust = "tukey")
#in console top part, 
```

# Follow up tests indicate (Tukey adjusted for multiple comparisons/pairwise comparisons) that petal length of Sertosa is significantly different from both Versicolor (t(147) = -32.51 , p < .001 ) and Virginica (t(147) = -47.521 , p <.001).
# Versicolor petal length is also significantly different than Virginica petal length (t (147)= -15.012, p < .001).

```{r}
priming_data %>%
  group_by(ID,relatedness,type)%>%
  count()
```

#install new package with multiple IVS
```{r}
#install.packages("datarium")
```

```{r}
data("jobsatisfaction", package = "datarium")
View(jobsatisfaction)
```

#to visualize
```{r}
jobsatisfaction%>%
ggplot()+
  geom_boxplot(mapping = aes(x = gender, y = score, fill = education_level))
```
#reminder interaction is intersecting lines on plot. difference in means between IV1s levels differ based on levels of IV2

#separate terms for main effects and interactions
```{r}
job_model = lm(data = jobsatisfaction, score ~ gender + education_level +gender:education_level)

car :: Anova(job_model)
```
#interaction with gender and education level. no main effect 
#An ANOVA was conducted. No main effect of gender was reported (F(1, 52)= 0.75, p = 0.392.
#There is a main effect of education level (F(2, 52)= 187.89, p < 0.001).
#There is also a significant interaction between gender and education (F(2, 52)= 7.339, p = 0.002)

#using this for pairwise comparisons

```{r}
emmeans :: emmeans (job_model,
                    pairwise~ gender | education_level,
                    adjust = "tukey")
```

#Looking for something goin on in the contrast area.
#Tukey adjust follow-up t-tyests indicate that male vs female job interaction level does not deviate significantly at the college or school level but males have higher job satusfaction at tge university level compared to females.
#ASSUMPTIONS
#lm is the assumption that data can be broken down linearly (no squared or cubed terms)
#normality of residuals. whatever is leftover from the model is normally distributed
#homogeneity of variance
#independence of variance. no within-subjects observations with data. all between-subjects

#Inspecting the model
```{r}
#install.packages("performance", dependencies = TRUE)
#install.packages("see", dependencies = TRUE)
#install.packages("patchwork", dependencies = TRUE)
```

```{r}
library(performance)
check_model(job_model)
```
#Gives you what is expected as a description and then shows you the plot of your data. Ours is not perefcet but it is okay.No major violations in assumptions were depicted here.

```{r}
priming_data %>% count()
```
#Checked that this has 492 particiopants

```{r}
rt_lm_model = lm(data = priming_data, rt ~relatedness + type + relatedness : type)
car :: Anova(rt_lm_model)
check_model(rt_lm_model)
```
#We have multiple observations for the same person because one person is doing the different conditions (unrelated shared and shared related), so we cannot use the ANOVA because this is not independent

#want to use Repeated Measure ANOVA for our data
```{r}
savic %>% 
  filter(typeoftrial == "target") %>%
  filter(relatedness %in% c("related", "unrelated") & type %in% c("direct", "shared")) %>% 
  group_by(ID, relatedness, type) %>% 
  count()
```
#Each participnat did 16 trials of each one with equal number of trials before exclusions.

#
```{r}
priming_data %>%
  group_by(ID, relatedness, type) %>%
  count()
```
#Incorrect trials or bad reaction time resulted in removing trials. Unbalanced reepeated measures (time)
#ANOVA limited by continuous DVs (accuracy is not continuous), can only do categorical IVs, cannot deal with missing data, cannot handle nestered/clustered data/ cannot handle unbalanced data

#solution is flexible LINEAR MIXED EFFECTS MODEL. parents of anova and t-test
```{r}
#install.packages("lmerTest")
library(lmerTest)

rt_model = lmer(data =priming_data, rt~ relatedness*type + (1|ID))
```
#lmer linear mixed effects model
#relatedness*type is shorthand for relatedness +type +
#unit of analysis is at the level of the individual

```{r}
car::Anova(rt_model)
nobs(rt_model)
check_model = rt_model
```
#report a chi square



#to display bar graph and points
```{r}
the_counts = jobsatisfaction %>%
  group_by(gender, education_level)%>%
  count()

```


```{r}
mean_stuff = jobsatisfaction %>%
group_by(gender, education_level) %>%
summarise(mean_score = mean(score),
            sd_score= sd(score))%>%
left_join (the_counts) %>%
mutate(SE = sd_score/n,
       ymin = mean_score - 1.96*SE,
       ymax = mean_score + 1.96*SE)
```

```{r}
mean_stuff %>%
  ggplot(mapping = aes(x = education_level, y = mean_score, group = gender, fill = gender))+
  geom_col( position = "dodge") +
  geom_errorbar(aes ( ymin = ymin, ymax = ymax),
                width = 0.25,
                position = position_dodge(width = 0.9))+
  geom_point(data = jobsatisfaction, aes (x = education_level, y = score, group = gender),
            position = position_jitterdodge(),
            alpha = 0.3)+
  theme_minimal()+
  labs( x = "education level", 
       y = "mean score")+
  scale_fill_manual(values = c("firebrick2", "lightblue"))
```



