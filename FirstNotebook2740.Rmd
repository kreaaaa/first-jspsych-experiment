---
title: "FirstNotebook2740"
output: html_document
date: "2024-10-15"
---

# install packages

```{r}
#install.packages("tidyverse")
```

# load packages

```{r}
library(tidyverse)
```

#plot iris
#plus indicates one chunk of code

```{r}
ggplot(data = iris)+
  geom_point(mapping = aes(x = Petal.Width, y = Petal.Length, color = Species, 
  size = Species, shape = Species))
```


```{r}
ggplot(data = iris)+
  geom_point(mapping = aes (x = Sepal.Width, y = Sepal.Length, color = Species,
    size = Species, shape = Species))
```

#displaying aggregate data

```{r}
ggplot(data = iris) +
  geom_col(mapping = aes (x = Species, y = Petal.Length, fill = "coral2"))
```

#load class data

```{r}
savic = read_csv("class_data.csv")
```

#basic info

```{r}
nrow(savic)

ncol(savic)

colnames(savic)

mean(savic$correct)
#won't work bc our columns dont have consistent data that is cutesy for R
#can't do an average for a string
#chr = strings and can't do math on strings
```

#histogram of RT

```{r}
ggplot(data = savic) +
  geom_histogram(mapping = aes (x = as.numeric(rt)))

range(as.numeric(savic$rt))

```

#tidyverse verbs

```{r}
objectdata = read_csv("objects.csv") %>%
  mutate(rt = as.numeric(rt),
         weight = as.factor(weight),
         shape = as.factor(shape))
         

#piping. end before the last line of code
#only columns selected. no simplifying rows
#filter for rows
#check correct and wany id


condition_data = objectdata %>%
  filter(typeoftrial == "picture" & weight %in% c("Heavy", "Light") & shape %in% c("Normal", "Smashed") & correct == TRUE) %>%
  select(subject, rt, weight, shape, correct)


#descriptive statistics

object_agg = condition_data %>%
  group_by(weight, shape) %>%
  summarise(mean_rt = mean(rt),
            sd_rt = sd(rt))
```

#plot

```{r}
ggplot(data = object_agg) +
  geom_col(mapping = aes(x = shape, y = mean_rt, fill = weight), position = "dodge") +
  theme_minimal()+
  labs(title = "plots of RTs")+
  scale_fill_manual(values = c("firebrick2", "lightblue"))
```

#class data analysis

```{r}
savic = read_csv("class_data.csv") %>%
  mutate(rt = as.numeric(rt),
         relatedness = as.factor(relatedness),
         type = as.factor(type))

levels(savic$relatedness)
#can look at levels when factors 

savic %>% group_by(ID) %>% count()

#want to just look target trials per ID
#sooooo

x= savic%>% filter(typeoftrial == "target") %>%
  group_by(ID) %>% count() %>% 
  filter (n!=104)
mean(x$n)
#to make sure everyone has the same number of trials


savic %>% 
  filter (typeoftrial == "target") %>%
  pull(rt)

savic%>%
  pull(ID)%>% unique() %>% length()

```

#attention fixing typos

```{r}
attention_trials= savic%>% 
  filter(typeoftrial == "attention") %>% 
  select(ID, response, novel1, novel2, novel3, correct) %>% 
    rowwise() %>%
  mutate(response = ifelse(is.na(response), "blank", response)) %>%
  mutate(across(c(novel1, novel2, novel3), ~ replace_na(., "NOT_FOUND"))) %>% 
  mutate(edit_novel1 = adist(novel1, response),
         edit_novel2 = adist(novel2, response),
         edit_novel3 = adist(novel3, response)) %>% 
  mutate(revised_correct = ifelse(edit_novel1 <= 2 |
                                    edit_novel2 <= 2 |
                                    edit_novel3 <= 2,
                                    1, 0),
          mismatch = ifelse(correct == revised_correct, 0, 1)) %>%
  ungroup()

  
```

#summarizing accuracy for attention trials

```{r}
attention_trials  %>% 
  summarize(mean_accuracy = mean(revised_correct), 
            sd_accuracy = sd(revised_correct))

## summarize participant accuracy 
subject_attention_accuracy = attention_trials  %>% 
  group_by(ID)  %>% 
  summarize(mean_accuracy = mean(revised_correct))

# find IDs with less than 75% accuracy
low_acc_IDs = subject_attention_accuracy  %>% 
  filter(mean_accuracy < 0.75)  %>% 
  pull(ID)
```

#need to filter based on rt in priming

```{r}
priming_data = savic %>% 
  filter(typeoftrial == "target") %>%
  select( ID, rt, relatedness, prime, response, type, correct, block_number, target, correct_key)  %>% 
  filter(!is.na(rt), rt > 200, rt <1500, correct == "TRUE", block_number == 1)  %>% 
  filter(relatedness  %in% c("related, unrelated") & type  %in% c("direct", "shared"))%>%
  filter (!ID  %in% low_acc_IDs)
```

#plot

```{r}
priming_data %>%
  group_by(type, relatedness) %>%
  summarise(mean_rt = mean(rt)) %>%
  ggplot() +
  geom_col(mapping = aes (x= type, y= mean_rt,
                          group = relatedness, fill = relatedness),
           position = "dodge") +
  theme_minimal()+
  scale_fill_manual(values = c("firebrick2", "lightblue"))
```

